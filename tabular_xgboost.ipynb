{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b576bcda",
   "metadata": {},
   "source": [
    "# Tabular XGBoost Baseline\n",
    "Tune the configuration in Cell 2, then run the remaining cells in order to train and evaluate the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc, precision_recall_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"XGBoost is required. Install via `pip install xgboost`.\") from exc\n",
    "\n",
    "CONFIG: Dict[str, Any] = {\n",
    "    'dataset': 'dataset/HI-Small_Trans.csv',\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'random_state': 42,\n",
    "    'max_samples': None,\n",
    "    'target_fpr': 0.05,\n",
    "    'report': None,\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.0,\n",
    "    'reg_lambda': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transactions(path: Path, max_samples: int | None) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if max_samples is not None and len(df) > max_samples:\n",
    "        df = df.sample(max_samples, random_state=42).reset_index(drop=True)\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            'From Bank': 'from_bank',\n",
    "            'To Bank': 'to_bank',\n",
    "            'Amount Received': 'amount_received',\n",
    "            'Receiving Currency': 'receiving_currency',\n",
    "            'Amount Paid': 'amount_paid',\n",
    "            'Payment Currency': 'payment_currency',\n",
    "            'Payment Format': 'payment_format',\n",
    "            'Is Laundering': 'is_laundering',\n",
    "        }\n",
    "    )\n",
    "    if 'Account' in df.columns:\n",
    "        df = df.rename(columns={'Account': 'from_account'})\n",
    "    if 'Account.1' in df.columns:\n",
    "        df = df.rename(columns={'Account.1': 'to_account'})\n",
    "    return df\n",
    "\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    work = df.copy()\n",
    "    work['timestamp'] = pd.to_datetime(work['Timestamp'], errors='coerce')\n",
    "    work['hour'] = work['timestamp'].dt.hour.fillna(-1).astype(int)\n",
    "    work['dayofweek'] = work['timestamp'].dt.dayofweek.fillna(-1).astype(int)\n",
    "    work['month'] = work['timestamp'].dt.month.fillna(-1).astype(int)\n",
    "    work['is_weekend'] = (work['dayofweek'] >= 5).astype(int)\n",
    "    work['same_bank'] = (work['from_bank'] == work['to_bank']).astype(int)\n",
    "    if 'from_account' in work.columns and 'to_account' in work.columns:\n",
    "        work['same_account'] = (work['from_account'] == work['to_account']).astype(int)\n",
    "    else:\n",
    "        work['same_account'] = 0\n",
    "    work['amount_diff'] = work['amount_received'] - work['amount_paid']\n",
    "    work['amount_ratio'] = np.divide(\n",
    "        work['amount_received'],\n",
    "        work['amount_paid'],\n",
    "        out=np.full(work.shape[0], np.nan, dtype=float),\n",
    "        where=work['amount_paid'].abs() > 0,\n",
    "    )\n",
    "    work['amount_ratio'] = np.where(np.isfinite(work['amount_ratio']), work['amount_ratio'], np.nan)\n",
    "    work['is_round_amount'] = ((work['amount_paid'] % 100) == 0).astype(int)\n",
    "\n",
    "    feature_cols = [\n",
    "        'amount_received',\n",
    "        'amount_paid',\n",
    "        'amount_diff',\n",
    "        'amount_ratio',\n",
    "        'hour',\n",
    "        'dayofweek',\n",
    "        'month',\n",
    "        'is_weekend',\n",
    "        'same_bank',\n",
    "        'same_account',\n",
    "        'is_round_amount',\n",
    "        'from_bank',\n",
    "        'to_bank',\n",
    "        'receiving_currency',\n",
    "        'payment_currency',\n",
    "        'payment_format',\n",
    "    ]\n",
    "    return work[feature_cols], work['is_laundering'].astype(int)\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    test_size: float,\n",
    "    val_size: float,\n",
    "    random_state: int,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.Series]:\n",
    "    X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=test_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    relative_val = val_size / (1.0 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_tmp,\n",
    "        y_tmp,\n",
    "        test_size=relative_val,\n",
    "        stratify=y_tmp,\n",
    "        random_state=random_state + 1,\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_numeric(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_val: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    numeric_cols: List[str],\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, StandardScaler]:\n",
    "    scaler = StandardScaler()\n",
    "    train_numeric = X_train[numeric_cols].copy()\n",
    "    medians = train_numeric.median()\n",
    "    train_numeric = train_numeric.fillna(medians)\n",
    "    scaler.fit(train_numeric)\n",
    "\n",
    "    def transform(df: pd.DataFrame) -> np.ndarray:\n",
    "        filled = df[numeric_cols].fillna(medians)\n",
    "        scaled = scaler.transform(filled)\n",
    "        return scaled.astype(np.float32)\n",
    "\n",
    "    train_array = transform(X_train)\n",
    "    val_array = transform(X_val)\n",
    "    test_array = transform(X_test)\n",
    "    return train_array, val_array, test_array, scaler\n",
    "\n",
    "\n",
    "def encode_categorical(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_val: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    categorical_cols: List[str],\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict[str, Dict[Any, int]]]:\n",
    "    mappings: Dict[str, Dict[Any, int]] = {}\n",
    "\n",
    "    def map_series(series: pd.Series, mapping: Dict[Any, int]) -> np.ndarray:\n",
    "        coded = series.map(mapping).fillna(0).astype(np.int32)\n",
    "        return coded.to_numpy()\n",
    "\n",
    "    train_encoded: List[np.ndarray] = []\n",
    "    val_encoded: List[np.ndarray] = []\n",
    "    test_encoded: List[np.ndarray] = []\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        uniques = X_train[col].dropna().unique().tolist()\n",
    "        mapping = {value: idx + 1 for idx, value in enumerate(uniques)}\n",
    "        mappings[col] = mapping\n",
    "        train_encoded.append(map_series(X_train[col], mapping))\n",
    "        val_encoded.append(map_series(X_val[col], mapping))\n",
    "        test_encoded.append(map_series(X_test[col], mapping))\n",
    "\n",
    "    train_array = np.stack(train_encoded, axis=1).astype(np.float32) if train_encoded else np.zeros((len(X_train), 0), dtype=np.float32)\n",
    "    val_array = np.stack(val_encoded, axis=1).astype(np.float32) if val_encoded else np.zeros((len(X_val), 0), dtype=np.float32)\n",
    "    test_array = np.stack(test_encoded, axis=1).astype(np.float32) if test_encoded else np.zeros((len(X_test), 0), dtype=np.float32)\n",
    "    return train_array, val_array, test_array, mappings\n",
    "\n",
    "\n",
    "def assemble_arrays(\n",
    "    numeric_train: np.ndarray,\n",
    "    numeric_val: np.ndarray,\n",
    "    numeric_test: np.ndarray,\n",
    "    categorical_train: np.ndarray,\n",
    "    categorical_val: np.ndarray,\n",
    "    categorical_test: np.ndarray,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    train_features = np.concatenate([numeric_train, categorical_train], axis=1)\n",
    "    val_features = np.concatenate([numeric_val, categorical_val], axis=1)\n",
    "    test_features = np.concatenate([numeric_test, categorical_test], axis=1)\n",
    "    return train_features, val_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_metrics(y_true: np.ndarray, y_prob: np.ndarray, threshold: float) -> Dict[str, Any]:\n",
    "    preds = (y_prob >= threshold).astype(int)\n",
    "    tp = int(np.sum((preds == 1) & (y_true == 1)))\n",
    "    fp = int(np.sum((preds == 1) & (y_true == 0)))\n",
    "    fn = int(np.sum((preds == 0) & (y_true == 1)))\n",
    "    tn = int(np.sum((preds == 0) & (y_true == 0)))\n",
    "    precision = tp / (tp + fp) if tp + fp else 0.0\n",
    "    recall = tp / (tp + fn) if tp + fn else 0.0\n",
    "    fpr = fp / (fp + tn) if fp + tn else 0.0\n",
    "    tnr = tn / (tn + fp) if tn + fp else 0.0\n",
    "    denom = precision + recall\n",
    "    f1 = (2 * precision * recall / denom) if denom else 0.0\n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'fpr': fpr,\n",
    "        'tnr': tnr,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn,\n",
    "    }\n",
    "\n",
    "\n",
    "def select_thresholds(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    target_fpr: float | None,\n",
    ") -> Dict[str, Dict[str, Any]]:\n",
    "    results: Dict[str, Dict[str, Any]] = {}\n",
    "    results['default'] = threshold_metrics(y_true, y_prob, 0.5)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    thresholds_extended = np.append(thresholds, 1.0)\n",
    "    denom = precision + recall\n",
    "    f1_scores = np.divide(\n",
    "        2 * precision * recall,\n",
    "        denom,\n",
    "        out=np.zeros_like(denom),\n",
    "        where=denom > 0,\n",
    "    )\n",
    "    best_idx = int(f1_scores.argmax())\n",
    "    best_threshold = float(thresholds_extended[best_idx])\n",
    "    results['best_f1'] = threshold_metrics(y_true, y_prob, best_threshold)\n",
    "\n",
    "    if target_fpr is not None:\n",
    "        grid = np.linspace(0.0, 1.0, num=501)\n",
    "        viable: List[Dict[str, Any]] = []\n",
    "        for candidate in grid:\n",
    "            metrics = threshold_metrics(y_true, y_prob, float(candidate))\n",
    "            if metrics['fpr'] <= target_fpr:\n",
    "                viable.append(metrics)\n",
    "        if viable:\n",
    "            results['target_fpr'] = max(viable, key=lambda item: item['recall'])\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_split(\n",
    "    model: xgb.XGBClassifier,\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    target_fpr: float | None,\n",
    ") -> Dict[str, Any]:\n",
    "    y_prob = model.predict_proba(features)[:, 1]\n",
    "    roc_auc = roc_auc_score(labels, y_prob)\n",
    "    precision, recall, _ = precision_recall_curve(labels, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    thresholds = select_thresholds(labels, y_prob, target_fpr)\n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'thresholds': thresholds,\n",
    "        'positive_rate': float(labels.mean()),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d958d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CONFIG.copy()\n",
    "df = load_transactions(Path(config['dataset']), config['max_samples'])\n",
    "X, y = engineer_features(df)\n",
    "numeric_cols = [\n",
    "    'amount_received',\n",
    "    'amount_paid',\n",
    "    'amount_diff',\n",
    "    'amount_ratio',\n",
    "    'hour',\n",
    "    'dayofweek',\n",
    "    'month',\n",
    "    'is_weekend',\n",
    "    'same_bank',\n",
    "    'same_account',\n",
    "    'is_round_amount',\n",
    "]\n",
    "categorical_cols = [\n",
    "    'from_bank',\n",
    "    'to_bank',\n",
    "    'receiving_currency',\n",
    "    'payment_currency',\n",
    "    'payment_format',\n",
    "]\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    X, y,\n",
    "    test_size=config['test_size'],\n",
    "    val_size=config['val_size'],\n",
    "    random_state=config['random_state'],\n",
    ")\n",
    "num_train, num_val, num_test, scaler = prepare_numeric(X_train, X_val, X_test, numeric_cols)\n",
    "cat_train, cat_val, cat_test, mappings = encode_categorical(X_train, X_val, X_test, categorical_cols)\n",
    "train_features, val_features, test_features = assemble_arrays(num_train, num_val, num_test, cat_train, cat_val, cat_test)\n",
    "y_train_np = y_train.to_numpy()\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "negatives = float((y_train_np == 0).sum())\n",
    "positives = float((y_train_np == 1).sum())\n",
    "scale_pos_weight = negatives / max(positives, 1.0)\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=config['n_estimators'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    max_depth=config['max_depth'],\n",
    "    subsample=config['subsample'],\n",
    "    colsample_bytree=config['colsample_bytree'],\n",
    "    gamma=config['gamma'],\n",
    "    reg_lambda=config['reg_lambda'],\n",
    "    objective='binary:logistic',\n",
    "    tree_method='hist',\n",
    "    eval_metric='aucpr',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=config['random_state'],\n",
    ")\n",
    "model.fit(train_features, y_train_np, eval_set=[(val_features, y_val_np)], verbose=False)\n",
    "val_metrics = evaluate_split(model, val_features, y_val_np, config['target_fpr'])\n",
    "test_metrics = evaluate_split(model, test_features, y_test_np, config['target_fpr'])\n",
    "print('=== Validation Metrics ===')\n",
    "print(f\"ROC AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "print(f\"PR AUC : {val_metrics['pr_auc']:.4f}\")\n",
    "print(f\"Positive prevalence: {val_metrics['positive_rate']:.4%}\")\n",
    "for name, detail in val_metrics['thresholds'].items():\n",
    "    print(f\"\\nThreshold strategy: {name}\")\n",
    "    for key, value in detail.items():\n",
    "        if key in {'tp', 'fp', 'fn', 'tn'}:\n",
    "            print(f\"  {key.upper():<3}: {value}\")\n",
    "        else:\n",
    "            print(f\"  {key:<10}: {value:.4f}\")\n",
    "print('\\n=== Test Metrics ===')\n",
    "print(f\"ROC AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "print(f\"PR AUC : {test_metrics['pr_auc']:.4f}\")\n",
    "print(f\"Positive prevalence: {test_metrics['positive_rate']:.4%}\")\n",
    "for name, detail in test_metrics['thresholds'].items():\n",
    "    print(f\"\\nThreshold strategy: {name}\")\n",
    "    for key, value in detail.items():\n",
    "        if key in {'tp', 'fp', 'fn', 'tn'}:\n",
    "            print(f\"  {key.upper():<3}: {value}\")\n",
    "        else:\n",
    "            print(f\"  {key:<10}: {value:.4f}\")\n",
    "if config['report']:\n",
    "    report_path = Path(config['report'])\n",
    "    report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    payload = {\n",
    "        'validation': val_metrics,\n",
    "        'test': test_metrics,\n",
    "    }\n",
    "    with report_path.open('w', encoding='utf-8') as handle:\n",
    "        json.dump(payload, handle, indent=2)\n",
    "    print(f\"\\nMetrics saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b0064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890b8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
