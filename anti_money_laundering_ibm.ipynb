{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib torch torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Minimal PyTorch CUDA availability check - fail fast if CUDA is unavailable\n",
    "try:\n",
    "    import torch\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"PyTorch is not installed or failed to import: {e}\")\n",
    "\n",
    "# Ensure CUDA is available - if not, raise an error because we rely on GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please ensure an NVIDIA GPU, drivers, and CUDA are installed and that the CUDA toolkit is compatible with your PyTorch build.\")\n",
    "\n",
    "# Report devices\n",
    "print('PyTorch version:', torch.__version__)\n",
    "cnt = torch.cuda.device_count()\n",
    "print('CUDA device count:', cnt)\n",
    "for i in range(cnt):\n",
    "    try:\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "    except Exception:\n",
    "        name = f'unknown-device-{i}'\n",
    "    print(f'Device {i}:', name)\n",
    "\n",
    "# Quick allocation test to confirm functional GPU access\n",
    "try:\n",
    "    _ = torch.zeros(1, device='cuda')\n",
    "    print('Successfully allocated a tensor on CUDA.')\n",
    "except Exception as e:\n",
    "    raise RuntimeError('CUDA appears available but tensor allocation failed: ' + str(e))\n",
    "\n",
    "# may need to use different dgl if not on linux or using different version of CUDA\n",
    "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.1/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternate dependencies for running on mac without CUDA (only run if previous block fails)\n",
    "\n",
    "!pip install pydantic\n",
    "!pip install PyYAML\n",
    "!pip install numpy==1.26.4\n",
    "!pip install torch==2.1.1 torchdata==0.7.1\n",
    "!pip install dgl -f https://data.dgl.ai/wheels/repo.html\n",
    "\n",
    "import torch\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the small transactions CSV (relative to this notebook).\n",
    "DATA_PATH = Path(\"dataset\") / \"HI-Small_Trans.csv\"\n",
    "\n",
    "# Load into a DataFrame\n",
    "small_trans = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Quick summary and preview\n",
    "print(f\"Loaded {len(small_trans)} rows; columns: {list(small_trans.columns)}\")\n",
    "small_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic analysis: currencies, banks, and other summaries\n",
    "# This cell is robust to different column names: it searches for currency-like and bank-like columns\n",
    "\n",
    "# Show shape and a small sample\n",
    "rows, cols = small_trans.shape\n",
    "print(f\"Data shape: {rows} rows x {cols} columns\")\n",
    "print()\n",
    "print(\"Sample rows:\")\n",
    "display(small_trans.head())\n",
    "\n",
    "# Missing values by column (top 10)\n",
    "missing_by_col = small_trans.isnull().sum().sort_values(ascending=False).head(15)\n",
    "print(\"Top missing values by column:\")\n",
    "print(missing_by_col.to_string())\n",
    "print()\n",
    "\n",
    "# Find likely currency column(s)\n",
    "currency_candidates = [c for c in small_trans.columns if any(k in c.lower() for k in ('currency','ccy','curr'))]\n",
    "if currency_candidates:\n",
    "    cur_col = currency_candidates[0]\n",
    "    num_currencies = small_trans[cur_col].nunique(dropna=True)\n",
    "    top_currencies = small_trans[cur_col].value_counts().head(10)\n",
    "    print(f\"Found currency column: '{cur_col}' — {num_currencies} unique values\")\n",
    "    print(\"Top currencies (by count):\")\n",
    "    print(top_currencies.to_string())\n",
    "else:\n",
    "    cur_col = None\n",
    "    print(\"No currency-like column found.\")\n",
    "    print(\"Columns:\", list(small_trans.columns))\n",
    "\n",
    "print()\n",
    "# Find likely bank-related columns\n",
    "bank_candidates = [c for c in small_trans.columns if any(k in c.lower() for k in ('bank','institution','bic','iban','bankid','bank_id','bankname','bank_name'))]\n",
    "if bank_candidates:\n",
    "    # Count unique bank identifiers across candidate columns\n",
    "    unique_banks = set()\n",
    "    for c in bank_candidates:\n",
    "        unique_banks.update(small_trans[c].dropna().astype(str).unique())\n",
    "    num_unique_banks = len(unique_banks)\n",
    "    print(f\"Found bank-like columns: {bank_candidates} — approx. {num_unique_banks} unique bank identifiers (aggregated)\")\n",
    "else:\n",
    "    num_unique_banks = None\n",
    "    print(\"No bank-like columns found.\")\n",
    "\n",
    "print()\n",
    "# Other basic summaries: amount column candidates and top senders/receivers if available\n",
    "amt_candidates = [c for c in small_trans.columns if any(k in c.lower() for k in ('amount','amt','value'))]\n",
    "if amt_candidates:\n",
    "    amt_col = amt_candidates[0]\n",
    "    print(f\"Found amount column: {amt_col} — summary:\")\n",
    "    print(small_trans[amt_col].describe())\n",
    "else:\n",
    "    print(\"No amount-like column found.\")\n",
    "\n",
    "# If sender/receiver columns exist, show top participants\n",
    "party_candidates = [c for c in small_trans.columns if any(k in c.lower() for k in ('sender','receiver','originator','beneficiary','from_','to_','account'))]\n",
    "if party_candidates:\n",
    "    print()\n",
    "    print(\"Top participants in party-like columns:\")\n",
    "    for c in party_candidates:\n",
    "        print(f\"Column: {c}\")\n",
    "# Final small sample\n",
    "display(small_trans.sample(min(5, len(small_trans))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# account numbers are in hexadecimal and need to be converted to int\n",
    "hex_to_int = np.vectorize(lambda x: int(x, 16))\n",
    "\n",
    "# create adjacency lists to represent the graph\n",
    "source = hex_to_int(small_trans['Account'])\n",
    "target = hex_to_int(small_trans['Account.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create directed graph using dgl\n",
    "g_accounts = dgl.graph((source, target))\n",
    "\n",
    "#remove isolated nodes\n",
    "g = dgl.compact_graphs(g_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# need to convert times from utc strings to unix floats\n",
    "utc_to_unix = np.vectorize(lambda x: pd.Timestamp(x).timestamp())\n",
    "\n",
    "# extract individual edge features\n",
    "time = utc_to_unix(small_trans['Timestamp'].values)\n",
    "amount_paid = small_trans['Amount Paid'].values\n",
    "amount_received = small_trans['Amount Received'].values\n",
    "\n",
    "# use one-hot encoding for categorical variables\n",
    "paid_enc = OneHotEncoder(sparse_output=False)\n",
    "paid_currency = paid_enc.fit_transform(small_trans['Payment Currency'].values.reshape(-1, 1))\n",
    "\n",
    "received_enc = OneHotEncoder(sparse_output=False)\n",
    "received_currency = received_enc.fit_transform(small_trans['Receiving Currency'].values.reshape(-1, 1))\n",
    "\n",
    "format_enc = OneHotEncoder(sparse_output=False)\n",
    "pay_format = format_enc.fit_transform(small_trans['Payment Format'].values.reshape(-1, 1))\n",
    "\n",
    "# combine edge features into single tensor\n",
    "edge_features = torch.cat((torch.transpose(torch.from_numpy(np.array([time, amount_paid, amount_received])), 0, 1), \n",
    "                           torch.from_numpy(paid_currency), torch.from_numpy(received_currency), torch.from_numpy(pay_format)), 1)\n",
    "\n",
    "# create y edge labels\n",
    "fraud_label = torch.tensor(small_trans['Is Laundering'].values)\n",
    "\n",
    "# attach features and labels to graph\n",
    "g.edata['features'] = edge_features\n",
    "g.edata['label'] = fraud_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use unshuffled 60/20/20 train/val/test split based on documentation\n",
    "train_edges, val_edges, test_edges = dgl.data.utils.split_dataset(torch.arange(g.num_edges()), frac_list=[0.6, 0.2, 0.2])\n",
    "\n",
    "train = dgl.edge_subgraph(g, train_edges)\n",
    "val = dgl.edge_subgraph(g, val_edges)\n",
    "test = dgl.edge_subgraph(g, test_edges)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOv070Al0cK/8N1oI0v7dEu",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
